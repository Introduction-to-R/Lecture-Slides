---
title: "Lecture1d"
author: "Amaury de Vicq"
date: "5/16/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

In this lecture, we will occupy ourselves (i.) identifying outliers and (ii.) missing value imputation (NA). This is a crucial step in the data cleaning process and is often necessary for any kind of succesful data analysis. This is because (i.) missing data might prevent functions to work properly, and (ii.) outliers could corrupt and/or bias to your results.

# Part 1: Missing Data Handling

## Basic guidelines
  
Raw, unclean data often has many missing data (NAs). Especially in economic history, this is very common and could be due to a variety of different reasons. It might be that some of the sources you are using to create your dataset has several unreadable entries, that you cannot access the sources and/or that some years are missing. While it might be possible to simply overlook these missing observations or delete them for your dataset, this is not always the best approach.     

In fact it is important to distinguish between three categories of missing data:
  - MCAR (missing completely at random)
  - MAR (missing at random)
  - MNAR (missing not at random)

These categories determine how to best solve the missing data issues. Some basic guidelines include:
  - If the amount of NAs < 5% and they are MCAR, it generally acceptable to simply delete them and/or to use functions with a built-in NA handling feature
  - If the amount of NAs > 5% and they are MCAR, it is better to use simple imputation methods such as mean imputation and interpolation
  - If they are MAR or MNAR it is often advised to rely on more complex imputation methods such as MICE (multiple imputation by chained equations)
  
## Simple methods for missing data treatment

## Uncovering missing data

Let us import some historical data  using the `readxl` package, we introduced in a previous lecture. As we will soon find out, this datasets contains many missing values (NAs). We will then discuss some simple methods to address this issue.

First, let us install the `readxl` package.

```{r eval = FALSE}
install.packages('readxl')
```

And don't forget to 'turn it on':

```{r}
library(readxl)
```

Now, let us import the dataset using 'read_xls' command:

```{r}
NL <- read_excel("data/Netherlands_GDPperCapita_TerritorialRef_1946_2012_CCode_528(1).xlsx")
```


The 'NL' dataset provides historical information on GDP per Capita for the Netherlands (1800-2010). It is derived direcly from the Clio-infra website, with some minor alterations for the purpose of this lecture. Before we go any further, let us have a closer look at the actual dataset. By doing so, we might uncover some common issues that could arise in your own projects as well. 

Recommended first steps in the analysis of all sorts of datasets are:
- the 'str' function which tells us how the dataeset is structured.
- the 'summary' function which provides some summary statistics regarding the dataset.
- and finally the 'head' function which (if set as default) provides an overview of the first 5 rows of the dataset. But this is optional.

```{r}
str(NL)
summary(NL)
head(NL)
```


![](data/lecture1d_1.png)


Using these functions, gives us detailed and necessary information about this dataset. We find that it consists of 211 observations accross 5 different variables. 'Country Code', 'Country name' and 'Indicator' are somewhat redudant as we already know that this dataset contains information on 'GDP per Capita' for the Netherlands, so we could remove them. 

More imporantly however, R recognises the variable 'Data' as a character instead of number or an integer, so we have to change this.

Using the following code, we will change 'Data' into a numeric variable, and drop column 1:3 (albeit this is optional!). We will save the new dataset as NLclean, so we can easily revert back to the old dataset when we chose to do so. We will then once more use the 'summary' function on the newly created NLclean dataset.

```{r}
library(dplyr)
NLclean <- NL %>%
            mutate(Data = as.numeric(Data)) %>%
            select(4,5)

str(NLclean)
summary(NLclean)
head(NLclean)

```


![](data/lecture1d_2.png)

Succes! We now have much easier to interpret dataset which shows the GDP per Capita for the Netherlands on a yearly basis for the period 1800-2010. More importantly, it tells us that there are 14 missing values (NAs). Uncovering these NAs is a crucial step.

## Deleting data, or relying on built-in NA handling features

Many function in R have a built-in NA handling feature. It is important to note that per default this function is often set to true, which means that the function will simply ignore the missing data. 





